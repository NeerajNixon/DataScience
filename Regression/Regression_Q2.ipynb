{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "20D070056_Q2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zi3Q-euuOJd0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vc4ndnSUOM_Y",
        "outputId": "caacf436-9672-4825-9fe9-e10eb79e24a6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OY2p2iXrOVQ_"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn import preprocessing"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoyNsdrzO8oU"
      },
      "source": [
        "# READING DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "truQmArFO-tC",
        "outputId": "b14aa6e4-25b8-4dca-8da7-f3727adcc16c"
      },
      "source": [
        "data=pd.read_excel('/content/drive/MyDrive/Colab Notebooks/data/haberman.xlsx')\n",
        "display(data)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X1</th>\n",
              "      <th>X2</th>\n",
              "      <th>X3</th>\n",
              "      <th>Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>30</td>\n",
              "      <td>64</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>30</td>\n",
              "      <td>62</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>30</td>\n",
              "      <td>65</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31</td>\n",
              "      <td>59</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>31</td>\n",
              "      <td>65</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>301</th>\n",
              "      <td>75</td>\n",
              "      <td>62</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>76</td>\n",
              "      <td>67</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>303</th>\n",
              "      <td>77</td>\n",
              "      <td>65</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>304</th>\n",
              "      <td>78</td>\n",
              "      <td>65</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>305</th>\n",
              "      <td>83</td>\n",
              "      <td>58</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>306 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     X1  X2  X3  Y\n",
              "0    30  64   1  1\n",
              "1    30  62   3  1\n",
              "2    30  65   0  1\n",
              "3    31  59   2  1\n",
              "4    31  65   4  1\n",
              "..   ..  ..  .. ..\n",
              "301  75  62   1  1\n",
              "302  76  67   0  1\n",
              "303  77  65   3  1\n",
              "304  78  65   1  2\n",
              "305  83  58   2  2\n",
              "\n",
              "[306 rows x 4 columns]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjJjEQK1Poik"
      },
      "source": [
        "# CHECKING FOR MISSING VALUES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kz6Hp7uqPrE1",
        "outputId": "8ff2fc5b-6b8c-4916-8d35-68123ee2b2ad"
      },
      "source": [
        "for col in data.columns.values:\n",
        "    \n",
        "    # Getting list of unique values in each column\n",
        "    unique_list = pd.unique(data[col])\n",
        "\n",
        "    print(\"Datatype of {} is: \".format(col), data[col].dtype)\n",
        "    print(\"Number of unique values for {} are: \".format(col), len(unique_list))\n",
        "\n",
        "    # Converting a column to a boolean array checking for null values\n",
        "    is_null = pd.isnull(data[col])\n",
        "\n",
        "    # Calculating total null values\n",
        "    total_null = np.sum(is_null)\n",
        "\n",
        "    print(\"Number of missing entries for {} are: \".format(col), total_null)\n",
        "    print(\"Number of non-missing entries for {} are: \".format(col), data[col].shape[0] - total_null)\n",
        "\n",
        "    print(\"---------------\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datatype of X1 is:  int64\n",
            "Number of unique values for X1 are:  49\n",
            "Number of missing entries for X1 are:  0\n",
            "Number of non-missing entries for X1 are:  306\n",
            "---------------\n",
            "Datatype of X2 is:  int64\n",
            "Number of unique values for X2 are:  12\n",
            "Number of missing entries for X2 are:  0\n",
            "Number of non-missing entries for X2 are:  306\n",
            "---------------\n",
            "Datatype of X3 is:  int64\n",
            "Number of unique values for X3 are:  31\n",
            "Number of missing entries for X3 are:  0\n",
            "Number of non-missing entries for X3 are:  306\n",
            "---------------\n",
            "Datatype of Y is:  int64\n",
            "Number of unique values for Y are:  2\n",
            "Number of missing entries for Y are:  0\n",
            "Number of non-missing entries for Y are:  306\n",
            "---------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PS3g15I4QER0"
      },
      "source": [
        "# CORRELATION MATRIX"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "vYMrtGJKQHVs",
        "outputId": "b5545147-11bf-4965-ca3f-60930e65ebeb"
      },
      "source": [
        "plt.figure(figsize = (15, 7))\n",
        "\n",
        "# Calculating correlation between all columns\n",
        "var_corr = data.corr()\n",
        "\n",
        "# Plotting correlation heatmap\n",
        "sns.heatmap(var_corr, xticklabels = var_corr.columns, yticklabels = var_corr.columns, annot = True, vmin=-1, vmax=1, center= 0)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f1107439f50>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJUEoenJQRyQ"
      },
      "source": [
        "# PRE-PROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "XjxLDbvBQUwr",
        "outputId": "d22ba405-e8b0-478e-ae88-572138326d3c"
      },
      "source": [
        "# Extracting the label column\n",
        "Y = data['Y']\n",
        "\n",
        "# Dropping the label column from the main dataset\n",
        "data = data.drop('Y', axis = 1)\n",
        "display(data)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X1</th>\n",
              "      <th>X2</th>\n",
              "      <th>X3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>30</td>\n",
              "      <td>64</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>30</td>\n",
              "      <td>62</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>30</td>\n",
              "      <td>65</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31</td>\n",
              "      <td>59</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>31</td>\n",
              "      <td>65</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>301</th>\n",
              "      <td>75</td>\n",
              "      <td>62</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>76</td>\n",
              "      <td>67</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>303</th>\n",
              "      <td>77</td>\n",
              "      <td>65</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>304</th>\n",
              "      <td>78</td>\n",
              "      <td>65</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>305</th>\n",
              "      <td>83</td>\n",
              "      <td>58</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>306 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     X1  X2  X3\n",
              "0    30  64   1\n",
              "1    30  62   3\n",
              "2    30  65   0\n",
              "3    31  59   2\n",
              "4    31  65   4\n",
              "..   ..  ..  ..\n",
              "301  75  62   1\n",
              "302  76  67   0\n",
              "303  77  65   3\n",
              "304  78  65   1\n",
              "305  83  58   2\n",
              "\n",
              "[306 rows x 3 columns]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGrwHr5xQhnh",
        "outputId": "d1d9c720-2f56-4707-e8d3-a9902233d0b3"
      },
      "source": [
        "# Converting the data into numpy arrays\n",
        "X = np.array(data)\n",
        "Y = np.array(Y)\n",
        "\n",
        "print(X.shape)\n",
        "print(Y.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(306, 3)\n",
            "(306,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10DGT-SqQpi_"
      },
      "source": [
        "# TRAIN -TEST SPLIT FUNCTION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SF6qNfAnQvNB"
      },
      "source": [
        "# Splitting the data into train and test sets\n",
        "def data_split(test_split = 0.2):\n",
        "    \n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = test_split, shuffle = True)\n",
        "    return X_train, X_test, Y_train, Y_test"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cP0Yaf24Qx5U"
      },
      "source": [
        "# LOGISTIC REGRESSION FUNCTION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pByyoh9Q5Fv"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "'''\n",
        "A function to carry out logistic regression\n",
        "\n",
        "Here, C is a parameter which specifies the inverse of the regularization strength, in a sense\n",
        "So, smaller values of C lead to stronger regularization\n",
        "'''\n",
        "\n",
        "def logistic_regression(X, Y, reg_inverse = 1.0, penalty = 'l2'):\n",
        "\n",
        "    clf = LogisticRegression(penalty = penalty, C = reg_inverse).fit(X, Y)\n",
        "    return clf"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXXoDQ3kQ7Bw"
      },
      "source": [
        "# CLASSIFICATION ERROR FUNCTION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBVes-DDRAuw"
      },
      "source": [
        "def classification_error(Y_pred, Y_actual):\n",
        "\n",
        "    # Total test values\n",
        "    total_entries = len(Y_pred)\n",
        "    \n",
        "    # Number of values wrongly predicted by the model\n",
        "    wrong_values = 0\n",
        "    \n",
        "    for i in range(total_entries):\n",
        "\n",
        "        if Y_pred[i] != Y_actual[i]:\n",
        "            wrong_values += 1\n",
        "\n",
        "    error = float(wrong_values)/float(total_entries)\n",
        "    return error"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROy5riexRC8s"
      },
      "source": [
        "# LOGISTIC REGRESSION WITH VARYING TRAIN-TEST SPLIT AND REGULARISATION STRENGTH"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDkAsVgPRSuV",
        "outputId": "e2cc4338-bafb-4ce7-eedb-c86de6267bc8"
      },
      "source": [
        "# Possible train-test splits\n",
        "test_splits = [0.1, 0.2, 0.3, 0.4]\n",
        "\n",
        "# Possible values of the inverse of the regularization strength\n",
        "reg_inverse_values = [0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30]\n",
        "\n",
        "for test_split in test_splits:\n",
        "\n",
        "    for reg_inverse_value in reg_inverse_values:\n",
        "\n",
        "        print(f\"Test Split Value: {test_split}\")\n",
        "        print(f\"Regularization Strength: {1/reg_inverse_value}\")\n",
        "        \n",
        "        X_train, X_test, Y_train, Y_test = data_split(test_split = test_split)\n",
        "        \n",
        "        # Normalizing the different features in the data\n",
        "        X_train = preprocessing.scale(X_train)\n",
        "        X_test = preprocessing.scale(X_test)\n",
        "        \n",
        "        # Fitting the data to the logistic regression model\n",
        "        clf = logistic_regression(X_train, Y_train)\n",
        "        \n",
        "        # Extract the coefficients of the trained logistic model\n",
        "        coef = clf.coef_\n",
        "\n",
        "        # Extract the intercept of the trained logistic model\n",
        "        intercept = clf.intercept_\n",
        "\n",
        "        print(f\"Coefficients of the trained logistic model are: {coef}\")\n",
        "        print(f\"Intercept of the trained logistic model is: {intercept}\")\n",
        "\n",
        "        # Carrying out predictions on the test data\n",
        "        Y_pred = clf.predict(X_test)\n",
        "        print(f\"The predicted survival status of the patients in the test dataset sre: {Y_pred}\")\n",
        "\n",
        "        # Computing the error in the predicted values\n",
        "        error = classification_error(Y_pred, Y_test)\n",
        "        print(f\"The classification error in the test data prediction is: {error} \\n\")\n",
        "\n",
        "        print(\"----------\\n\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Split Value: 0.1\n",
            "Regularization Strength: 100.0\n",
            "Coefficients of the trained logistic model are: [[ 0.22521022 -0.01550829  0.72872251]]\n",
            "Intercept of the trained logistic model is: [-1.06186171]\n",
            "The predicted survival status of the patients in the test dataset sre: [1 1 1 2 2 1 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "The classification error in the test data prediction is: 0.22580645161290322 \n",
            "\n",
            "----------\n",
            "\n",
            "Test Split Value: 0.1\n",
            "Regularization Strength: 33.333333333333336\n",
            "Coefficients of the trained logistic model are: [[0.22904658 0.00733051 0.55583078]]\n",
            "Intercept of the trained logistic model is: [-1.02724263]\n",
            "The predicted survival status of the patients in the test dataset sre: [1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1]\n",
            "The classification error in the test data prediction is: 0.16129032258064516 \n",
            "\n",
            "----------\n",
            "\n",
            "Test Split Value: 0.1\n",
            "Regularization Strength: 10.0\n",
            "Coefficients of the trained logistic model are: [[ 0.19615663 -0.03470716  0.64269005]]\n",
            "Intercept of the trained logistic model is: [-1.05348256]\n",
            "The predicted survival status of the patients in the test dataset sre: [1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 2 1 1 1 1 1]\n",
            "The classification error in the test data prediction is: 0.22580645161290322 \n",
            "\n",
            "----------\n",
            "\n",
            "Test Split Value: 0.1\n",
            "Regularization Strength: 3.3333333333333335\n",
            "Coefficients of the trained logistic model are: [[ 0.20069763 -0.05595321  0.63421182]]\n",
            "Intercept of the trained logistic model is: [-1.05218726]\n",
            "The predicted survival status of the patients in the test dataset sre: [1 1 1 1 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1]\n",
            "The classification error in the test data prediction is: 0.1935483870967742 \n",
            "\n",
            "----------\n",
            "\n",
            "Test Split Value: 0.1\n",
            "Regularization Strength: 1.0\n",
            "Coefficients of the trained logistic model are: [[0.19882752 0.01127152 0.67013393]]\n",
            "Intercept of the trained logistic model is: [-1.09377177]\n",
            "The predicted survival status of the patients in the test dataset sre: [1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "The classification error in the test data prediction is: 0.3548387096774194 \n",
            "\n",
            "----------\n",
            "\n",
            "Test Split Value: 0.1\n",
            "Regularization Strength: 0.3333333333333333\n",
            "Coefficients of the trained logistic model are: [[ 0.16343815 -0.04163216  0.62897553]]\n",
            "Intercept of the trained logistic model is: [-1.08471718]\n",
            "The predicted survival status of the patients in the test dataset sre: [1 1 1 1 1 1 1 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2]\n",
            "The classification error in the test data prediction is: 0.25806451612903225 \n",
            "\n",
            "----------\n",
            "\n",
            "Test Split Value: 0.1\n",
            "Regularization Strength: 0.1\n",
            "Coefficients of the trained logistic model are: [[ 0.19105828 -0.07823269  0.62544125]]\n",
            "Intercept of the trained logistic model is: [-0.99135691]\n",
            "The predicted survival status of the patients in the test dataset sre: [1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "The classification error in the test data prediction is: 0.12903225806451613 \n",
            "\n",
            "----------\n",
            "\n",
            "Test Split Value: 0.1\n",
            "Regularization Strength: 0.03333333333333333\n",
            "Coefficients of the trained logistic model are: [[ 0.18798915 -0.10016513  0.63027506]]\n",
            "Intercept of the trained logistic model is: [-1.03026652]\n",
            "The predicted survival status of the patients in the test dataset sre: [1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "The classification error in the test data prediction is: 0.16129032258064516 \n",
            "\n",
            "----------\n",
            "\n",
            "Test Split Value: 0.2\n",
            "Regularization Strength: 100.0\n",
            "Coefficients of the trained logistic model are: [[ 0.28580807 -0.34583653  0.61533691]]\n",
            "Intercept of the trained logistic model is: [-1.21307801]\n",
            "The predicted survival status of the patients in the test dataset sre: [1 1 1 1 2 1 1 1 2 1 2 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1]\n",
            "The classification error in the test data prediction is: 0.3064516129032258 \n",
            "\n",
            "----------\n",
            "\n",
            "Test Split Value: 0.2\n",
            "Regularization Strength: 33.333333333333336\n",
            "Coefficients of the trained logistic model are: [[0.22071019 0.05400436 0.55469283]]\n",
            "Intercept of the trained logistic model is: [-1.0392172]\n",
            "The predicted survival status of the patients in the test dataset sre: [1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1\n",
            " 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "The classification error in the test data prediction is: 0.20967741935483872 \n",
            "\n",
            "----------\n",
            "\n",
            "Test Split Value: 0.2\n",
            "Regularization Strength: 10.0\n",
            "Coefficients of the trained logistic model are: [[ 0.379534   -0.09615686  0.70684484]]\n",
            "Intercept of the trained logistic model is: [-1.07277694]\n",
            "The predicted survival status of the patients in the test dataset sre: [1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1\n",
            " 1 1 1 2 1 1 1 1 1 2 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1]\n",
            "The classification error in the test data prediction is: 0.24193548387096775 \n",
            "\n",
            "----------\n",
            "\n",
            "Test Split Value: 0.2\n",
            "Regularization Strength: 3.3333333333333335\n",
            "Coefficients of the trained logistic model are: [[ 0.24791543 -0.06407422  0.65828738]]\n",
            "Intercept of the trained logistic model is: [-1.11814148]\n",
            "The predicted survival status of the patients in the test dataset sre: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1\n",
            " 1 2 2 1 1 1 1 1 1 1 1 1 1 2 1 1 2 1 1 1 1 1 1 1 1]\n",
            "The classification error in the test data prediction is: 0.2903225806451613 \n",
            "\n",
            "----------\n",
            "\n",
            "Test Split Value: 0.2\n",
            "Regularization Strength: 1.0\n",
            "Coefficients of the trained logistic model are: [[0.15937363 0.05910316 0.60806515]]\n",
            "Intercept of the trained logistic model is: [-1.06324972]\n",
            "The predicted survival status of the patients in the test dataset sre: [1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1 1 1]\n",
            "The classification error in the test data prediction is: 0.25806451612903225 \n",
            "\n",
            "----------\n",
            "\n",
            "Test Split Value: 0.2\n",
            "Regularization Strength: 0.3333333333333333\n",
            "Coefficients of the trained logistic model are: [[ 0.37783408 -0.00723987  0.6512051 ]]\n",
            "Intercept of the trained logistic model is: [-1.10774473]\n",
            "The predicted survival status of the patients in the test dataset sre: [1 2 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 2 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 2 1 1 2 1 1 1 1 1 1 1 1 1 1 1]\n",
            "The classification error in the test data prediction is: 0.25806451612903225 \n",
            "\n",
            "----------\n",
            "\n",
            "Test Split Value: 0.2\n",
            "Regularization Strength: 0.1\n",
            "Coefficients of the trained logistic model are: [[0.08930045 0.01417277 0.75918935]]\n",
            "Intercept of the trained logistic model is: [-1.01437207]\n",
            "The predicted survival status of the patients in the test dataset sre: [1 1 1 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1\n",
            " 1 2 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "The classification error in the test data prediction is: 0.25806451612903225 \n",
            "\n",
            "----------\n",
            "\n",
            "Test Split Value: 0.2\n",
            "Regularization Strength: 0.03333333333333333\n",
            "Coefficients of the trained logistic model are: [[ 0.28562663 -0.02552743  0.66638402]]\n",
            "Intercept of the trained logistic model is: [-1.10415906]\n",
            "The predicted survival status of the patients in the test dataset sre: [1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1]\n",
            "The classification error in the test data prediction is: 0.25806451612903225 \n",
            "\n",
            "----------\n",
            "\n",
            "Test Split Value: 0.3\n",
            "Regularization Strength: 100.0\n",
            "Coefficients of the trained logistic model are: [[ 0.20891341 -0.01257548  0.59636872]]\n",
            "Intercept of the trained logistic model is: [-1.09588169]\n",
            "The predicted survival status of the patients in the test dataset sre: [1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2]\n",
            "The classification error in the test data prediction is: 0.25 \n",
            "\n",
            "----------\n",
            "\n",
            "Test Split Value: 0.3\n",
            "Regularization Strength: 33.333333333333336\n",
            "Coefficients of the trained logistic model are: [[ 0.2800726  -0.04353785  0.53017755]]\n",
            "Intercept of the trained logistic model is: [-1.22470896]\n",
            "The predicted survival status of the patients in the test dataset sre: [1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "The classification error in the test data prediction is: 0.29347826086956524 \n",
            "\n",
            "----------\n",
            "\n",
            "Test Split Value: 0.3\n",
            "Regularization Strength: 10.0\n",
            "Coefficients of the trained logistic model are: [[0.31288791 0.05651965 0.8530738 ]]\n",
            "Intercept of the trained logistic model is: [-0.95874965]\n",
            "The predicted survival status of the patients in the test dataset sre: [1 1 1 2 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 1 2 1 1 1 2 1 1 2 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "The classification error in the test data prediction is: 0.2391304347826087 \n",
            "\n",
            "----------\n",
            "\n",
            "Test Split Value: 0.3\n",
            "Regularization Strength: 3.3333333333333335\n",
            "Coefficients of the trained logistic model are: [[ 0.08166321 -0.12449873  0.55512115]]\n",
            "Intercept of the trained logistic model is: [-0.92821608]\n",
            "The predicted survival status of the patients in the test dataset sre: [1 1 1 1 1 1 2 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 1 1 1 1 2 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1]\n",
            "The classification error in the test data prediction is: 0.17391304347826086 \n",
            "\n",
            "----------\n",
            "\n",
            "Test Split Value: 0.3\n",
            "Regularization Strength: 1.0\n",
            "Coefficients of the trained logistic model are: [[ 0.11045892 -0.0421862   0.70748877]]\n",
            "Intercept of the trained logistic model is: [-0.88539596]\n",
            "The predicted survival status of the patients in the test dataset sre: [1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 2 1 2 1 2 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1]\n",
            "The classification error in the test data prediction is: 0.25 \n",
            "\n",
            "----------\n",
            "\n",
            "Test Split Value: 0.3\n",
            "Regularization Strength: 0.3333333333333333\n",
            "Coefficients of the trained logistic model are: [[0.07868868 0.00237527 0.55013038]]\n",
            "Intercept of the trained logistic model is: [-0.9765378]\n",
            "The predicted survival status of the patients in the test dataset sre: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 2 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2\n",
            " 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2 1 1]\n",
            "The classification error in the test data prediction is: 0.21739130434782608 \n",
            "\n",
            "----------\n",
            "\n",
            "Test Split Value: 0.3\n",
            "Regularization Strength: 0.1\n",
            "Coefficients of the trained logistic model are: [[ 0.19835557 -0.07247235  0.75021571]]\n",
            "Intercept of the trained logistic model is: [-1.11636569]\n",
            "The predicted survival status of the patients in the test dataset sre: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 2\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1\n",
            " 1 1 1 2 2 1 2 1 2 1 1 1 1 1 1 1 1 2]\n",
            "The classification error in the test data prediction is: 0.29347826086956524 \n",
            "\n",
            "----------\n",
            "\n",
            "Test Split Value: 0.3\n",
            "Regularization Strength: 0.03333333333333333\n",
            "Coefficients of the trained logistic model are: [[ 0.16292814 -0.05663444  0.6134857 ]]\n",
            "Intercept of the trained logistic model is: [-1.16852793]\n",
            "The predicted survival status of the patients in the test dataset sre: [2 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1\n",
            " 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 1 1]\n",
            "The classification error in the test data prediction is: 0.29347826086956524 \n",
            "\n",
            "----------\n",
            "\n",
            "Test Split Value: 0.4\n",
            "Regularization Strength: 100.0\n",
            "Coefficients of the trained logistic model are: [[0.20251186 0.11390475 0.57641567]]\n",
            "Intercept of the trained logistic model is: [-1.09232053]\n",
            "The predicted survival status of the patients in the test dataset sre: [2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2\n",
            " 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 2 1 1 2\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "The classification error in the test data prediction is: 0.21951219512195122 \n",
            "\n",
            "----------\n",
            "\n",
            "Test Split Value: 0.4\n",
            "Regularization Strength: 33.333333333333336\n",
            "Coefficients of the trained logistic model are: [[ 0.20210039 -0.05469714  0.68541396]]\n",
            "Intercept of the trained logistic model is: [-1.06465128]\n",
            "The predicted survival status of the patients in the test dataset sre: [1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1\n",
            " 1 1 2 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1\n",
            " 1 1 1 1 1 1 2 1 1 1 1 1]\n",
            "The classification error in the test data prediction is: 0.25203252032520324 \n",
            "\n",
            "----------\n",
            "\n",
            "Test Split Value: 0.4\n",
            "Regularization Strength: 10.0\n",
            "Coefficients of the trained logistic model are: [[ 0.34289718 -0.31305776  1.08248891]]\n",
            "Intercept of the trained logistic model is: [-0.94430757]\n",
            "The predicted survival status of the patients in the test dataset sre: [1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2 1 1 2 1 1 1 1 2 2 1 1 1 1 1 1\n",
            " 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 2 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 2 1 1 1 1]\n",
            "The classification error in the test data prediction is: 0.2764227642276423 \n",
            "\n",
            "----------\n",
            "\n",
            "Test Split Value: 0.4\n",
            "Regularization Strength: 3.3333333333333335\n",
            "Coefficients of the trained logistic model are: [[0.01179713 0.01855124 0.70974614]]\n",
            "Intercept of the trained logistic model is: [-1.11673487]\n",
            "The predicted survival status of the patients in the test dataset sre: [1 1 1 1 1 1 1 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 2 1 2 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "The classification error in the test data prediction is: 0.2845528455284553 \n",
            "\n",
            "----------\n",
            "\n",
            "Test Split Value: 0.4\n",
            "Regularization Strength: 1.0\n",
            "Coefficients of the trained logistic model are: [[ 0.41438378 -0.05804643  0.76330659]]\n",
            "Intercept of the trained logistic model is: [-1.02533449]\n",
            "The predicted survival status of the patients in the test dataset sre: [2 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1\n",
            " 2 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2\n",
            " 1 1 1 1 1 1 1 2 1 1 1 1]\n",
            "The classification error in the test data prediction is: 0.25203252032520324 \n",
            "\n",
            "----------\n",
            "\n",
            "Test Split Value: 0.4\n",
            "Regularization Strength: 0.3333333333333333\n",
            "Coefficients of the trained logistic model are: [[ 0.29641481 -0.08391437  0.77566881]]\n",
            "Intercept of the trained logistic model is: [-0.95188105]\n",
            "The predicted survival status of the patients in the test dataset sre: [2 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 2 1 1 2 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2\n",
            " 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 2 1 1 1 1 1 1]\n",
            "The classification error in the test data prediction is: 0.22764227642276422 \n",
            "\n",
            "----------\n",
            "\n",
            "Test Split Value: 0.4\n",
            "Regularization Strength: 0.1\n",
            "Coefficients of the trained logistic model are: [[0.32513846 0.07976434 0.43098394]]\n",
            "Intercept of the trained logistic model is: [-1.08773971]\n",
            "The predicted survival status of the patients in the test dataset sre: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 2 1 1 2 1 1 1 1 1 1 1]\n",
            "The classification error in the test data prediction is: 0.24390243902439024 \n",
            "\n",
            "----------\n",
            "\n",
            "Test Split Value: 0.4\n",
            "Regularization Strength: 0.03333333333333333\n",
            "Coefficients of the trained logistic model are: [[0.37571763 0.00172233 0.47558035]]\n",
            "Intercept of the trained logistic model is: [-1.258371]\n",
            "The predicted survival status of the patients in the test dataset sre: [1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1\n",
            " 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "The classification error in the test data prediction is: 0.3089430894308943 \n",
            "\n",
            "----------\n",
            "\n"
          ]
        }
      ]
    }
  ]
}